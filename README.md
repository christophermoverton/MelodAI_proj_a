
#  MelodAI - MIDI Music Generation with GPT

This project uses a GPT-style transformer to generate symbolic music based on MIDI data, using the `miditok` library and Magenta's classical datasets. This guide walks you through setting up the environment using **WSL (Windows Subsystem for Linux)**.

---

##  WSL Setup Instructions

### 1. Install WSL (if not already installed)

Open PowerShell as Administrator and run:

```bash
wsl --install
```

> If you're already using WSL1, you can upgrade to WSL2 with:
> ```bash
> wsl --set-default-version 2
> ```

Then restart your machine if prompted.

### 2. Open WSL and Update Your Linux Distro

```bash
sudo apt update && sudo apt upgrade -y
```

---

##  Python Environment Setup

### 3. Install Python and pip (if not available)

```bash
sudo apt install python3 python3-pip python3-venv -y
```

### 4. Clone the Repository

```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

### 5. Create and Activate a Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

> If you see permission errors, try:  
> `chmod +x venv/bin/activate`

---

##  Install Dependencies

### 6. Install Python Packages

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

---

##  Directory Structure (Typical)

```
project/
â”œâ”€â”€ data/                  # MIDI files
â”œâ”€â”€ outputs/               # Model outputs
â”œâ”€â”€ checkpoints/           # Saved models
â”œâ”€â”€ tokenizer_configs/     # Miditok tokenizer files
â”œâ”€â”€ venv/                  # Python virtual environment
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ main.ipynb             # Training or generation notebook
```
---
##  Download the MAESTRO Dataset

Download the **MAESTRO** dataset from the official Magenta site:

ðŸ”— [https://magenta.tensorflow.org/datasets/maestro](https://magenta.tensorflow.org/datasets/maestro)

Once downloaded, extract the contents into the following directory path:

```bash
MelodAI/
â””â”€â”€ data/
    â””â”€â”€ maestro/
        â””â”€â”€ maestro-v3.0.0/
            â”œâ”€â”€ 2004/
            â”‚   â”œâ”€â”€ MIDI-Unprocessed_04_R1_2004_01.mid
            â”‚   â””â”€â”€ ...
            â”œâ”€â”€ 2006/
            â””â”€â”€ ...
```
---

##  Running the Project

Use Jupyter, VS Code, or run scripts directly in terminal.

### Launch Jupyter (inside venv):

```bash
pip install notebook
jupyter notebook
```

---

##  Notes

- Ensure all MIDI files are placed in the `data/` folder.
- Use `tokenizer.train()` if building a new tokenizer from scratch.
- Save your trained tokenizer and model for reuse.

---

##  Deactivating the Environment

```bash
deactivate
```

---

##  License

MIT License. See `LICENSE` for details.
```

